

````markdown
# ğŸ­ **Linear Regression Architecture Workshop â€” Robot Failure Prediction (MLOps Ready)**

---

## âœ… **Executive Summary**
This project delivers a **Univariate Linear Regression** solution to **predict when the next robot failure is likely to occur** using robot sensor signals (Axis measurements).  
We implement Linear Regression in **two approaches**â€”**from scratch** (gradient descent) and **scikit-learn**â€”then compare metrics and generate clear graphs as evidence.  
The solution follows **MLOps-style architecture**: modular code, config-driven experiments, reproducible runs, and experiment tracking.

---

## ğŸ¯ **Problem Statement**
Manufacturing robots generate continuous sensor data. Failures are expensive and often detected too late.  
Our goal is to use one key sensor feature (example: `Axis #1`) to predict:

âœ… **Time remaining until the next failure event** (example: `time_to_failure_days`)

This supports **Predictive Maintenance**, allowing proactive alerts such as:  
ğŸ“Œ **â€œRaise an alert ~2 weeks before a likely failure.â€**

---

## âœ… **Workshop Deliverables**

### ğŸ“š **Session 1 â€” Linear Regression**
- Loaded robot CSV into Pandas and inspected data quality
- Preprocessed data (missing values, normalization, train/test split)
- Implemented **manual Linear Regression** (MSE + Gradient Descent)
- Implemented **scikit-learn Linear Regression** for comparison
- Evaluated using **RMSE, MAE, RÂ²**
- Produced regression plots to show model fit

### âš™ï¸ **Session 2 â€” MLOps Architecture**
- Refactored notebook logic into modular scripts (`src/`)
- Parameterized experiments using YAML config (`configs/experiment_config.yaml`)
- Saved experiment outputs to:
  - `experiments/results.csv` (**metrics tracking**)
  - `experiments/plots/` (**visual proof**)
- Ensured reproducibility: anyone can clone + run and get the same outputs

---

## ğŸ“Œ **How â€œFailureâ€ is Defined in This Workshop**
The dataset does not contain a direct `failure = 1` column.  
So we define failure events using an explainable rule based on abnormal sensor behavior:

- Compute anomaly score (example: rolling **z-score**) on a selected axis
- Mark a **failure event** when sensor deviation crosses a threshold
- Compute target label:

âœ… `time_to_failure_days = (next_failure_time - current_time)`

Then the Linear Regression learns this mapping:

**Sensor Axis value â†’ Time remaining until next failure**

---

## ğŸ§  **What Each Module Does (3 Lines Each)**

### `src/data_loader.py`
- Loads robot sensor data from CSV (and supports DB/API expansion later).
- Ensures consistent DataFrame structure and clean column handling.
- Supplies standardized inputs for failure-time prediction.

### `src/preprocessing.py`
- Cleans missing values, sorts by time, and normalizes features.
- Builds the prediction label: **time until next failure**.
- Outputs model-ready `X` (sensor axis) and `y` (time-to-failure).

### `src/model.py`
- Implements Linear Regression **from scratch** using gradient descent.
- Runs scikit-learn LinearRegression for baseline comparison.
- Produces predicted values for **time until next failure**.

### `src/evaluation.py`
- Calculates RMSE, MAE, and RÂ² for model performance.
- Generates regression plots and residual diagnostics.
- Saves visual proof and performance metrics for reporting.

### `src/run_experiment.py`
- Orchestrates the full pipeline using YAML config.
- Executes preprocessing â†’ training â†’ evaluation â†’ saving outputs.
- Produces repeatable results to predict **next failure timing**.

### `configs/experiment_config.yaml`
- Stores all experiment settings (paths, feature axis, thresholds, learning rate, epochs).
- Enables reruns without changing code (config-driven workflow).
- Defines what â€œfailure predictionâ€ means for a run.

---

## ğŸ“Š **Outputs Produced**

### âœ… 1) Experiment Tracking
ğŸ“„ **`experiments/results.csv`**
- Stores metrics for scratch vs scikit-learn models:
  - **RMSE**
  - **MAE**
  - **RÂ²**
  - Run tag / timestamp for tracking

### âœ… 2) Visual Proof (Plots)
ğŸ“ Saved under **`experiments/plots/`**
- **Scatter + Regression line** (model fit)
- **Residual plot** (error distribution)

---

## â–¶ï¸ **How to Run the Project (Step-by-step)**

### 1) Create + activate virtual environment
```powershell
python -m venv .venv
.\.venv\Scripts\activate
````

### 2) Install dependencies

```powershell
pip install -r requirements.txt
```

### 3) Run the full pipeline (recommended)

```powershell
python -m src.run_experiment
```

### 4) View results

* Metrics: `experiments/results.csv`
* Plots: `experiments/plots/`

---

## ğŸ““ **Notebooks (For Presentation)**

### `notebooks/EDA.ipynb`

* Explores data quality, missing values, distributions, and feature behavior.
* Helps justify the selected sensor axis for prediction.

### `notebooks/linear_regression.ipynb`

* Shows manual LR vs scikit-learn comparison.
* Displays plots and metrics in a presentation-ready format.

### `notebooks/RobotPM_MLOps.ipynb`

* Documents the MLOps refactor and modular architecture.
* Highlights config-driven execution and experiment tracking outputs.

---

## ğŸ–¥ï¸ **Optional: Run Dashboard**

If you want a UI to view the dataset/stream:

```powershell
streamlit run dashboard/app.py
```

---

## ğŸ§¾ **Key MLOps Design Decisions**

* âœ… **Separation of Concerns:** loader, preprocessing, model, evaluation are separate modules
* âœ… **Config-Driven:** all tunable parameters are in YAML (no hard-coded values)
* âœ… **Experiment Tracking:** results saved in `experiments/results.csv`
* âœ… **Reproducibility:** same config + same code = same outputs

---



```

If you want it to look even more â€œpremiumâ€ on GitHub, tell me your repo name + whether you want a **Screenshots section** (plots + results.csv) and Iâ€™ll add a clean gallery layout.
```
