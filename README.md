# ğŸ¤– Robot Predictive Maintenance â€” Neon + Live Streaming Alerts + Dashboard

**Executive intent:** turn raw robot telemetry into **actionable predictive-maintenance signals** using  
(1) **model training + learned thresholds**, (2) **live streaming detection**, and (3) a **dashboard** â€” all persisted in **Neon (Postgres)**.

---

## ğŸ§  Problem

Industrial robots produce continuous sensor readings (current/axis signals). Failures are expensive and often detected late.  
This project watches streaming signals and raises early warnings:

- âš ï¸ **ALERT** â†’ abnormal behavior emerging (schedule maintenance soon)
- ğŸ›‘ **ERROR** â†’ high-risk abnormality (urgent intervention)

---

## âœ… What You Can Demo (Deliverables)

### 1) Notebook: Training + Threshold Learning (Neon)
File: `notebooks/01_train_models_thresholds_neon.ipynb`

What it does:
- Load historical robot dataset
- Fit a **Linear Regression baseline** (per robot / per signal)
- Compute residual-based thresholds:
  - `residual_alert` (early warning)
  - `residual_error` (critical)
- Save trained params + thresholds into Neon: `linear_regression.models`

### 2) Notebook: Live Streaming + Alerts + Event Logging (Neon)
File: `notebooks/02_streaming_alerts_dashboard_neon.ipynb`

What it does:
- Stream recent points per robot (smooth + readable)
- Plot per-robot panels:
  - observed signal
  - smoothed signal
  - regression baseline
  - threshold bands
  - âš ï¸ / ğŸ›‘ markers when events trigger
- Save events to:
  - `experiments/events.log` (local audit log)
  - `linear_regression.events` (Neon table)

### 3) Dashboard (Streamlit)
File: `dashboard/app.py`

What it does:
- Pull latest stream + events from Neon
- Show per-robot â€œoperator viewâ€
- Summarize events over a lookback window

---

## ğŸ§± Architecture (High-Level)

**Raw CSV â†’ training pipeline â†’ models in Neon â†’ streaming detector â†’ events in Neon â†’ dashboard**

- **Data layer:** CSV + Neon Postgres (persistent, dashboard-ready)
- **Model layer:** linear regression baseline (interpretable, fast)
- **Detection layer:** residual thresholding + cooldown to reduce alert spam
- **Observability:** events.log + Neon `events` table + dashboard panels

---

## ğŸ“ Project Structure

```text
.
â”œâ”€ configs/
â”œâ”€ dashboard/
â”‚  â””â”€ app.py
â”œâ”€ data/
â”‚  â”œâ”€ processed/
â”‚  â”‚  â””â”€ processed_robot_data.csv
â”‚  â””â”€ raw/
â”‚     â””â”€ RMBR4-2_export_test_with_robotids_*.csv
â”œâ”€ experiments/
â”‚  â”œâ”€ plots/
â”‚  â”‚  â”œâ”€ robot_1_live.html
â”‚  â”‚  â”œâ”€ robot_2_live.html
â”‚  â”‚  â”œâ”€ robot_3_live.html
â”‚  â”‚  â””â”€ robot_4_live.html
â”‚  â”œâ”€ events_log.csv
â”‚  â”œâ”€ events_robot_1.csv
â”‚  â”œâ”€ events_robot_2.csv
â”‚  â”œâ”€ events_robot_3.csv
â”‚  â”œâ”€ events_robot_4.csv
â”‚  â”œâ”€ events.log
â”‚  â””â”€ results.csv
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_train_models_thresholds_neon.ipynb
â”‚  â”œâ”€ 02_streaming_alerts_dashboard_neon.ipynb
â”‚  â””â”€ Optional-Notebook(practise).ipynb
â”œâ”€ screenshots/
â”œâ”€ venv/                 # local virtual environment (donâ€™t commit)
â”œâ”€ .flake8
â”œâ”€ .gitignore
â”œâ”€ README.md
â””â”€ requirements.txt
```

---

## âš™ï¸ Setup

### 1) Create & activate a virtual environment
```bash
python -m venv .venv
# Windows PowerShell
.\.venv\Scripts\activate
```

### 2) Install dependencies
```bash
pip install -r requirements.txt
```

### 3) Configure Neon connection
Create a `.env` file in the project root:

```env
PGHOST=xxxxx.neon.tech
PGDATABASE=xxxx
PGUSER=xxxx
PGPASSWORD=xxxx
PGPORT=5432
PGSSLMODE=require
```

---

## â–¶ï¸ How to Run (Correct Order)

### Step 1 â€” Train models + save thresholds to Neon
Run:
- `notebooks/01_train_models_thresholds_neon.ipynb`

Expected:
- âœ… `linear_regression.models` populated (typically 4 robots / 4 rows)
- Threshold values visible in output tables/prints

### Step 2 â€” Run streaming + generate events + save logs
Run:
- `notebooks/02_streaming_alerts_dashboard_neon.ipynb`

Expected:
- 4 robot plots with baseline + threshold bands
- âš ï¸ and ğŸ›‘ markers appear when residual exceeds thresholds
- `experiments/events.log` is written/updated
- âœ… `linear_regression.events` populates as streaming runs

### Step 3 â€” Launch the Streamlit dashboard

After you finish **Notebook 2** (it generates the latest streaming events/logs), start the dashboard from your project root:

**Windows (PowerShell / CMD):**
```bash
streamlit run dashboard\\app.py
```

**macOS / Linux:**
```bash
streamlit run dashboard/app.py
```

Expected:
- Robot panels + recent events summary pulled from Neon
- A local URL like `http://localhost:8501`


---

## ğŸ—ƒï¸ Database Tables (Neon)

Common tables used/created:
- `linear_regression.models` â†’ model coefficients + thresholds
- `linear_regression.events` â†’ alert/error events with timestamps
- (optional in your implementation) `training_points`, `stream_points`

---

## ğŸ“Œ Key Design Choices (and how to explain them)

### Why a Linear Regression baseline?
- Interpretable and fast â†’ perfect baseline for workshop-grade predictive maintenance
- Easier to validate than complex models (clear â€œexpected vs observedâ€)

### Why residual-based thresholds?
- Residual = **observed âˆ’ expected**
- Converts continuous deviation into actionable categories:
  - `residual_alert` = early anomaly
  - `residual_error` = critical anomaly

### Why cooldown logic?
- Streaming detectors can spam repeated alerts
- Cooldown improves signal-to-noise and creates a cleaner operator experience

### Why Neon DB?
- Production-like persistence (not just notebook memory)
- Enables dashboard queries and reproducible demos

---

### 30-second overview
- â€œThis project turns robot sensor streams into predictive-maintenance alerts.â€
- â€œWe learn thresholds from historical data, then apply them on streaming data in real time.â€
- â€œAll models and events persist to Neon, and Streamlit shows an operator dashboard.â€

### Notebook 1 (Training + thresholds)
- â€œThis notebook fits a baseline model to learn what *normal* looks like.â€
- â€œResidual thresholds become our ALERT/ERROR rules and are stored in `linear_regression.models`.â€

### Notebook 2 (Streaming + alerts)
- â€œHere we stream points and compare observed vs expected in real time.â€
- â€œWhen residual crosses the learned thresholds, we log âš ï¸/ğŸ›‘ events to both a file and Neon.â€

### Dashboard
- â€œThis is the operator view: it pulls the latest signals and events directly from Neon.â€
- â€œThe key idea is end-to-end reproducibility: data â†’ model â†’ events â†’ dashboard.â€

---

## âœ… Submission Checklist

- [ ] Notebooks run end-to-end on a fresh machine after `pip install -r requirements.txt`
- [ ] `.env` is present locally and **NOT committed**
- [ ] `linear_regression.models` has rows after Notebook 1
- [ ] `linear_regression.events` populates after Notebook 2 streaming
- [ ] Dashboard launches and shows recent events

---

## Author

**Param Avinashkumar Rasaniya**  
Course: Predictive Maintenance / Streaming Analytics Workshop
